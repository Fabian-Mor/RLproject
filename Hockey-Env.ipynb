{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T13:16:44.712167Z",
     "start_time": "2025-01-14T13:16:44.461684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import hockey.hockey_env as h_env\n",
    "import gymnasium as gym\n",
    "from importlib import reload\n",
    "import time"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T13:16:44.744180Z",
     "start_time": "2025-01-14T13:16:44.728233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.set_printoptions(suppress=True)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T13:16:44.791901Z",
     "start_time": "2025-01-14T13:16:44.753213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "reload(h_env)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabia\\PycharmProjects\\ReinforcementProject\\.venv\\lib\\site-packages\\gymnasium\\envs\\registration.py:642: UserWarning: \u001B[33mWARN: Overriding environment Hockey-v0 already in registry.\u001B[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
      "C:\\Users\\fabia\\PycharmProjects\\ReinforcementProject\\.venv\\lib\\site-packages\\gymnasium\\envs\\registration.py:642: UserWarning: \u001B[33mWARN: Overriding environment Hockey-One-v0 already in registry.\u001B[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'hockey.hockey_env' from 'C:\\\\Users\\\\fabia\\\\PycharmProjects\\\\ReinforcementProject\\\\.venv\\\\lib\\\\site-packages\\\\hockey\\\\hockey_env.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Normal Game Play"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T13:16:45.602379Z",
     "start_time": "2025-01-14T13:16:45.588347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "env = h_env.HockeyEnv()"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "have a look at the initialization condition: alternating who starts and are random in puck position"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T13:16:48.177402Z",
     "start_time": "2025-01-14T13:16:45.691436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "obs, info = env.reset()\n",
    "obs_agent2 = env.obs_agent_two()\n",
    "_ = env.render()"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "one episode with random agents"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T13:16:52.060088Z",
     "start_time": "2025-01-14T13:16:48.204350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "obs, info = env.reset()\n",
    "obs_agent2 = env.obs_agent_two()\n",
    "\n",
    "for _ in range(600):\n",
    "    env.render(mode=\"human\")\n",
    "    a1 = np.random.uniform(-1,1,4)\n",
    "    a2 = np.random.uniform(-1,1,4)    \n",
    "    obs, r, d, t, info = env.step(np.hstack([a1,a2]))    \n",
    "    obs_agent2 = env.obs_agent_two()\n",
    "    if d or t: break"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Without rendering, it runs much faster"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\"info\" dict contains useful proxy rewards and winning information"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T13:17:10.290760Z",
     "start_time": "2025-01-14T13:17:10.280235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "info, env.get_info_agent_two()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'winner': 1,\n",
       "  'reward_closeness_to_puck': 0.0,\n",
       "  'reward_touch_puck': 0.0,\n",
       "  'reward_puck_direction': 0.0032131561279296877},\n",
       " {'winner': -1,\n",
       "  'reward_closeness_to_puck': -0.10249135635850666,\n",
       "  'reward_touch_puck': 0.0,\n",
       "  'reward_puck_direction': -0.0032131561279296877})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Winner == 0: draw\n",
    "\n",
    "Winner == 1: you (left player)\n",
    "\n",
    "Winner == -1: opponent wins (right player)"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T13:17:11.253379Z",
     "start_time": "2025-01-14T13:17:11.056891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "env.close()"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Train Shooting"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T14:33:22.121330Z",
     "start_time": "2025-01-14T14:33:22.113806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "env = h_env.HockeyEnv(mode=h_env.Mode.TRAIN_SHOOTING)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T14:33:39.063257Z",
     "start_time": "2025-01-14T14:33:38.664774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "o, info = env.reset()\n",
    "_ = env.render()\n",
    "\n",
    "for _ in range(50):\n",
    "    env.render()\n",
    "    a1 = [1,0,0,1] # np.random.uniform(-1,1,4)\n",
    "    a2 = [0,0.,0,0] \n",
    "    obs, r, d, t , info = env.step(np.hstack([a1,a2]))\n",
    "    obs_agent2 = env.obs_agent_two()\n",
    "    if d or t: break"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T14:33:46.071625Z",
     "start_time": "2025-01-14T14:33:45.879590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "env.close()"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Train DEFENDING"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T14:33:47.805609Z",
     "start_time": "2025-01-14T14:33:47.789723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "env = h_env.HockeyEnv(mode=h_env.Mode.TRAIN_DEFENSE)"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T14:33:55.324678Z",
     "start_time": "2025-01-14T14:33:53.715062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "o, info = env.reset()\n",
    "_ = env.render()\n",
    "\n",
    "for _ in range(60):\n",
    "    env.render()\n",
    "    a1 = [0.1,0,0,1] # np.random.uniform(-1,1,3)\n",
    "    a2 = [0,0.,0,0] \n",
    "    obs, r, d, t, info = env.step(np.hstack([a1,a2]))\n",
    "    print(r)\n",
    "    obs_agent2 = env.obs_agent_two()\n",
    "    if d or t: break"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "-0.48387062152583005\n",
      "-0.3477316841618804\n",
      "-0.24112985475069587\n",
      "-0.1612129315434362\n",
      "-0.10203283513954238\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "10.0\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T14:34:12.222768Z",
     "start_time": "2025-01-14T14:34:12.023188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "env.close()"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Using discrete actions"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import random"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "env = h_env.HockeyEnv(mode=h_env.Mode.TRAIN_SHOOTING)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "env.reset()\n",
    "for _ in range(251):\n",
    "    env.render()\n",
    "    a1_discrete = random.randint(0,7)\n",
    "    a1 = env.discrete_to_continous_action(a1_discrete)\n",
    "    a2 = [0,0.,0,0 ] \n",
    "    obs, r, d, t, info = env.step(np.hstack([a1,a2]))    \n",
    "    obs_agent2 = env.obs_agent_two()\n",
    "    if d or t: break"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "env.close()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Hand-crafted Opponent"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "env = h_env.HockeyEnv()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "o, info = env.reset()\n",
    "_ = env.render()\n",
    "player1 = h_env.BasicOpponent(weak=False)\n",
    "player2 = h_env.BasicOpponent()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "obs_buffer = []\n",
    "reward_buffer=[]\n",
    "obs, info = env.reset()\n",
    "obs_agent2 = env.obs_agent_two()\n",
    "for _ in range(251):\n",
    "    env.render()\n",
    "    a1 = player1.act(obs)\n",
    "    a2 = player2.act(obs_agent2)\n",
    "    obs, r, d, t, info = env.step(np.hstack([a1,a2]))    \n",
    "    obs_buffer.append(obs)\n",
    "    reward_buffer.append(r)\n",
    "    obs_agent2 = env.obs_agent_two()\n",
    "    if d or t: break\n",
    "obs_buffer = np.asarray(obs_buffer)\n",
    "reward_buffer = np.asarray(reward_buffer)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "np.mean(obs_buffer,axis=0)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "np.std(obs_buffer,axis=0)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "If you want to use a fixed observation scaling, this might be a reasonable choice"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "scaling = [ 1.0,  1.0 , 0.5, 4.0, 4.0, 4.0,  \n",
    "            1.0,  1.0,  0.5, 4.0, 4.0, 4.0,  \n",
    "            2.0, 2.0, 10.0, 10.0, 4,0 ,4,0]"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.plot(obs_buffer[:,2])\n",
    "plt.plot(obs_buffer[:,8])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.plot(obs_buffer[:,12])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.plot(reward_buffer[:])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "np.sum(reward_buffer)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "info2 = env.get_info_agent_two()\n",
    "info, info2, env.get_reward(info), env.get_reward_agent_two(info2)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "env.close()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Human Opponent"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "env = h_env.HockeyEnv()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "player1 = h_env.HumanOpponent(env=env, player=1)\n",
    "player2 = h_env.BasicOpponent()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "player1 = h_env.BasicOpponent()\n",
    "player2 = h_env.HumanOpponent(env=env, player=2)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "obs, info = env.reset()\n",
    "\n",
    "env.render()\n",
    "time.sleep(1)\n",
    "obs_agent2 = env.obs_agent_two()\n",
    "for _ in range(100):\n",
    "    time.sleep(0.2)\n",
    "    env.render()\n",
    "    a1 = player1.act(obs) \n",
    "    a2 = player2.act(obs_agent2)\n",
    "    obs, r, d, _, info = env.step(np.hstack([a1,a2]))    \n",
    "    obs_agent2 = env.obs_agent_two()\n",
    "    if d: break"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "env.close()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Check side consistency"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "env = h_env.HockeyEnv()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "o, info = env.reset()\n",
    "_ = env.render()\n",
    "player1 = h_env.BasicOpponent(weak=False)\n",
    "player2 = h_env.BasicOpponent(weak=False)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "obs_buffer = []\n",
    "reward_buffer=[]\n",
    "obs2_buffer = []\n",
    "winner_buffer = []\n",
    "reward2_buffer=[]\n",
    "for game in range(1000):\n",
    "    obs, info = env.reset()\n",
    "    obs_agent2 = env.obs_agent_two()\n",
    "    for _ in range(500):\n",
    "        # env.render()\n",
    "        a1 = player1.act(obs)\n",
    "        a2 = player2.act(obs_agent2)\n",
    "#        a1 = np.random.uniform(-1,1,4)\n",
    "#        a2 = np.random.uniform(-1,1,4)    \n",
    "        obs, r, d, t, info = env.step(np.hstack([a1,a2]))\n",
    "        info2 = env.get_info_agent_two()\n",
    "        r2 = env.get_reward_agent_two(info2)\n",
    "        obs_buffer.append(obs)\n",
    "        obs_agent2 = env.obs_agent_two()\n",
    "        obs2_buffer.append(obs_agent2)\n",
    "        reward_buffer.append(r)\n",
    "        reward2_buffer.append(r2)\n",
    "        if d or t:\n",
    "            winner_buffer.append(info[\"winner\"])\n",
    "            break\n",
    "obs_buffer = np.asarray(obs_buffer)\n",
    "reward_buffer = np.asarray(reward_buffer)\n",
    "obs2_buffer = np.asarray(obs2_buffer)\n",
    "reward2_buffer = np.asarray(reward2_buffer)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "obs_buffer.shape"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "np.mean(obs_buffer,axis=0)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "(np.std(obs_buffer,axis=0) - np.std(obs2_buffer,axis=0)) / np.std(obs_buffer,axis=0)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "winner_buffer"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "np.mean(winner_buffer,axis=0)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "np.std(winner_buffer,axis=0)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "np.sum(reward_buffer), np.sum(reward2_buffer)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "env.close()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
